{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b7e0d5",
   "metadata": {},
   "source": [
    "## Classifying MNIST with Le-Net (MyGrad and MyNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37cced",
   "metadata": {},
   "source": [
    "In this notebook, we will be training a convolutional neural network (using the Le-Net design described in [this paper](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)) to classify hand-written digits. We will be using the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), which contains labeled images of hand-written digits from 0 to 9. The MNIST dataset has a training set of 60,000 images and a test set of 10,000 images. \n",
    "\n",
    "You should have downloaded the [DataSets repo](https://github.com/CogWorksBWSI/DataSets), installed it, and set it up using `python setup.py develop` within that directory. This provides you with the mnist dataset, and a function for loading it, which we will use below.\n",
    "\n",
    "We will be replicating the famous \"LeNet\" CNN architecture, which was one of the first convolutional neural network designs. We will explain the architecture and operations used in convolutional neural nets throughout this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6eec21",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mygrad as mg\n",
    "from mygrad import Tensor\n",
    "\n",
    "from noggin import create_plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c285df",
   "metadata": {},
   "source": [
    "### MNIST Data Loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de80c7b",
   "metadata": {},
   "source": [
    "First, we will load in our data using handy functions from the datasets repo. If you haven't already, download the data by calling `download_mnist()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd4673",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from datasets import load_mnist, download_mnist\n",
    "download_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5bafa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# loading in the dataset with train/test data/labels\n",
    "x_train, y_train, x_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ff11f",
   "metadata": {},
   "source": [
    "What is the shape and data-types of these arrays? What is the shape of each individual image? How many color-channels does each number have.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31599e",
   "metadata": {},
   "source": [
    "Let's plot some examples from the MNIST dataset below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c60c01",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "img_id = 5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_train[img_id, 0], cmap=\"gray\")\n",
    "ax.set_title(f\"truth: {y_train[img_id]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce3da7",
   "metadata": {},
   "source": [
    "We will want to turn these 28x28 images into 32x32 images, for the sake of compatibility with the convolutions that we want to do. We can simply pad two rows/columns of zeros to all sides of the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453f753",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# zero-pad the images\n",
    "x_train = np.pad(x_train, ((0, 0), (0, 0), (2, 2), (2, 2)), mode=\"constant\")\n",
    "x_test = np.pad(x_test, ((0, 0), (0, 0), (2, 2), (2, 2)), mode=\"constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160431c6",
   "metadata": {},
   "source": [
    "The original images stored unsigned 8bit integers for their pixel values. We need to convert these to floating-point values. Let's convert the images (not the labels) 32-bit floats.\n",
    "You can use the `.astype()` array method to do this, and specify either `np.float32` or `\"float32\"` in the method call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327ef15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2216f2",
   "metadata": {},
   "source": [
    "Finally, we need to normalize these images. With cifar-10, we shifted the images by the mean and divided by the standard deviation. Here, let's be a little laze and simply normalize the images so that their pixel values lie on $[0, 1]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e72c1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459a0e1",
   "metadata": {},
   "source": [
    "Complete the following classification accuracy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, truth):\n",
    "    \"\"\"\n",
    "    Returns the mean classification accuracy for a batch of predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : Union[numpy.ndarray, mg.Tensor], shape=(M, D)\n",
    "        The scores for D classes, for a batch of M data points\n",
    "\n",
    "    truth : numpy.ndarray, shape=(M,)\n",
    "        The true labels for each datum in the batch: each label is an\n",
    "        integer in [0, D)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The fraction of predictions that indicated the correct class.\n",
    "    \"\"\"\n",
    "    # STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62deeef2",
   "metadata": {},
   "source": [
    "## The \"LeNet\" Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fb6e9",
   "metadata": {},
   "source": [
    "In the convnet to classify MNIST images, we will construct a CNN with two convolutional layers each structured as: \n",
    "\n",
    "```\n",
    "conv layer --> relu --> pooling layer\n",
    "```\n",
    "\n",
    ", followed by two dense layers with a relu between them. Thus our network is:\n",
    "\n",
    "```\n",
    "CONV -> RELU -> POOL -> CONV -> RELU -> POOL -> FLATTEN -> DENSE -> RELU -> DENSE -> SOFTMAX\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d41570",
   "metadata": {},
   "source": [
    "### Layer Details\n",
    "\n",
    "CONV-1: 20 filters, 5x5 filter size, stride-1\n",
    "\n",
    "POOL-1: 2x2, stride-2\n",
    "\n",
    "CONV-2: 10 filters, 5x5 filter size, stride-1\n",
    "\n",
    "POOL-2: 2x2, stride-2\n",
    "\n",
    "DENSE-3: 20 neurons\n",
    "\n",
    "DENSE-4: size-???  # hint: what should the dimensionality of our output be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d2fcb",
   "metadata": {},
   "source": [
    "### Activations\n",
    "\n",
    "We will be using the \"Glorot Uniform\" initialization scheme for all of our layers' weights (the biases will be 0, which is the default). If you would like to read more about how Xavier Glorot explains the rationalization behind these weight initializations, look here for [his paper written with Yoshua Bengio](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf).\n",
    "\n",
    "This initialization scheme takes an additional \"gain parameter\", which will be $\\sqrt{2}$ for us. Use the following syntax for specifying this gain:\n",
    "\n",
    "```python\n",
    "from mygrad.nnet.initializers import glorot_uniform\n",
    "\n",
    "gain = {'gain': np.sqrt(2)}\n",
    "\n",
    "# E.g. initializing a dense layer with glorot-uniform initialization\n",
    "# and a gain of root-2\n",
    "dense(d1, d2, \n",
    "      weight_initializer=glorot_uniform, \n",
    "      weight_kwargs=gain)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c159dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynn.layers.conv import conv\n",
    "from mynn.layers.dense import dense\n",
    "\n",
    "from mygrad.nnet.initializers import glorot_uniform\n",
    "from mygrad.nnet.activations import relu\n",
    "from mygrad.nnet.layers import max_pool\n",
    "from mygrad.nnet.losses import softmax_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your `Model`-MyNN class for the architecture prescribed above.\n",
    "\n",
    "class Model:\n",
    "    ''' A simple convolutional neural network. '''\n",
    "    def __init__(self, num_input_channels, f1, f2, d1, num_classes):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_input_channels : int\n",
    "            The number of channels for a input datum\n",
    "            \n",
    "        f1 : int\n",
    "            The number of filters in conv-layer 1\n",
    "        \n",
    "        f2 : int\n",
    "            The number of filters in conv-layer 2\n",
    "\n",
    "        d1 : int\n",
    "            The number of neurons in dense-layer 1\n",
    "        \n",
    "        num_classes : int\n",
    "            The number of classes predicted by the model.\n",
    "        \"\"\"\n",
    "        # Initialize your two convolution layers and two dense layers each \n",
    "        # as class attributes using the functions imported from MyNN\n",
    "        #\n",
    "        # We will use `weight_initializer=glorot_uniform` for all 4 layers\n",
    "        \n",
    "        # Note that you will need to compute `input_size` for\n",
    "        # dense layer 1 : the number of elements being produced by the preceding conv\n",
    "        # layer\n",
    "        # STUDENT CODE HERE\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        ''' Defines a forward pass of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray, shape=(N, 1, 32, 32)\n",
    "            The input data, where N is the number of images.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(N, num_classes)\n",
    "            The class scores for each of the N images.\n",
    "        '''\n",
    "        \n",
    "        # Define the \"forward pass\" for this model based on the architecture detailed above.\n",
    "        # Note that, to compute \n",
    "        # We know the new dimension given the formula: out_size = ((in_size - filter_size)/stride) + 1\n",
    "    \n",
    "        # STUDENT CODE HERE\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" A convenience function for getting all the parameters of our model. \"\"\"\n",
    "        # Create a list of every parameter contained in the 4 layers you wrote in your __init__ function\n",
    "        # STUDENT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88e275",
   "metadata": {},
   "source": [
    "Initialize the SGD-optimizer. We will be adding a new feature to our update method, known as [\"momentum\"](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum). The following is a sensible configuration for the optimizer:\n",
    "\n",
    "```python\n",
    "SGD(<your model parameters>, learning_rate=0.01, momentum=0.9, weight_decay=5e-04)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ba6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SGD and initialize it as described above\n",
    "# Also initialize your model\n",
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fe99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter, fig, ax = create_plot([\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a325c",
   "metadata": {},
   "source": [
    "Using a batch-size of 100, train your convolutional neural network. Try running through 1 epoch of your data (i.e. enough batches to have processed your entire training data set once) - this may take a while. Plot training-loss and training accuracy, via noggin, for each batch. After each epoch, measure the *test* accuracy of your model on the entire test set - do not perform backprop for this stage. You should find that your network gets excellent performance.\n",
    "\n",
    "Reference the cifar-10 (solution) notebook for guidance on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba42bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3714ed",
   "metadata": {},
   "source": [
    "Referencing the matplotlib code at the top of the notebook, visualize some images and check your model's predictions for them.\n",
    "\n",
    "Also, use your model and the truth data to find images that the model *fails* to get right - plot some of these fail cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "nbsphinx"
  },
  "kernelspec": {
   "display_name": "Python [conda env:week2]",
   "language": "python",
   "name": "conda-env-week2-py"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
